{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96072743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea308452",
   "metadata": {},
   "source": [
    "### Setup detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d325d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference - https://github.com/facebookresearch/detectron2\n",
    "\n",
    "# Install detectron2 that matches the above pytorch version\n",
    "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
    "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
    "#!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu113/torch1.10/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e143e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "setup_logger(name=\"mask2former\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c914c33",
   "metadata": {},
   "source": [
    "### Setup Mask2Former"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51057ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference - https://github.com/facebookresearch/Mask2Former\n",
    "\n",
    "%cd /pt/segmentation\n",
    "\n",
    "import os\n",
    "m2f_dir_exists = os.path.exists(os.path.join(os.getcwd(), 'Mask2Former'))\n",
    "if not m2f_dir_exists:\n",
    "    print('Cloning https://github.com/facebookresearch/Mask2Former.git')\n",
    "    !git clone https://github.com/facebookresearch/Mask2Former.git\n",
    "%cd /pt/segmentation/Mask2Former\n",
    "\n",
    "!pip install -U opencv-python\n",
    "!pip install git+https://github.com/cocodataset/panopticapi.git\n",
    "!pip install -r requirements.txt\n",
    "%cd mask2former/modeling/pixel_decoder/ops\n",
    "!python setup.py build install\n",
    "%cd ../../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b68c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile MultiScaleDeformableAttention CUDA op - Restart Kernel afterwards\n",
    "%cd /pt/segmentation/Mask2Former/mask2former/modeling/pixel_decoder/ops/\n",
    "!sh /pt/segmentation/Mask2Former/mask2former/modeling/pixel_decoder/ops/make.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf58c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /pt/segmentation/Mask2Former/\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.projects.deeplab import add_deeplab_config\n",
    "coco_metadata = MetadataCatalog.get(\"coco_2017_val_panoptic\")\n",
    "\n",
    "# import Mask2Former project\n",
    "from mask2former import add_maskformer2_config\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e93ff76",
   "metadata": {},
   "source": [
    "### Image setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e295af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference - https://github.com/googlecolab/colabtools/blob/main/google/colab/patches/__init__.py\n",
    "\n",
    "import cv2\n",
    "from IPython import display\n",
    "import PIL\n",
    "\n",
    "\n",
    "def cv2_imshow(a):\n",
    "  \"\"\"A replacement for cv2.imshow() for use in Jupyter notebooks.\n",
    "  Args:\n",
    "    a : np.ndarray. shape (N, M) or (N, M, 1) is an NxM grayscale image. shape\n",
    "      (N, M, 3) is an NxM BGR color image. shape (N, M, 4) is an NxM BGRA color\n",
    "      image.\n",
    "  \"\"\"\n",
    "  a = a.clip(0, 255).astype('uint8')\n",
    "  # cv2 stores colors as BGR; convert to RGB\n",
    "  if a.ndim == 3:\n",
    "    if a.shape[2] == 4:\n",
    "      a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
    "    else:\n",
    "      a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "  display.display(PIL.Image.fromarray(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aceb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://images.cocodataset.org/val2017/000000005477.jpg -q -O /pt/segmentation/input/plane.jpg\n",
    "\n",
    "image_name = \"plane.jpg\"\n",
    "im = cv2.imread(\"/pt/segmentation/input/\" + image_name)\n",
    "cv2_imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8f86e3",
   "metadata": {},
   "source": [
    "### Run predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89913b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "add_deeplab_config(cfg)\n",
    "add_maskformer2_config(cfg)\n",
    "cfg.merge_from_file(\"configs/coco/panoptic-segmentation/swin/maskformer2_swin_large_IN21k_384_bs16_100ep.yaml\")\n",
    "cfg.MODEL.WEIGHTS = 'https://dl.fbaipublicfiles.com/maskformer/mask2former/coco/panoptic/maskformer2_swin_large_IN21k_384_bs16_100ep/model_final_f07440.pkl'\n",
    "cfg.MODEL.MASK_FORMER.TEST.SEMANTIC_ON = True\n",
    "cfg.MODEL.MASK_FORMER.TEST.INSTANCE_ON = True\n",
    "cfg.MODEL.MASK_FORMER.TEST.PANOPTIC_ON = True\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7015847",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = predictor(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14ed2a3",
   "metadata": {},
   "source": [
    "### Show predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show panoptic/instance/semantic predictions: \n",
    "v = Visualizer(im[:, :, ::-1], coco_metadata, scale=1.2, instance_mode=ColorMode.IMAGE_BW)\n",
    "panoptic_result = v.draw_panoptic_seg(outputs[\"panoptic_seg\"][0].to(\"cpu\"), outputs[\"panoptic_seg\"][1]).get_image()\n",
    "\n",
    "v = Visualizer(im[:, :, ::-1], coco_metadata, scale=1.2, instance_mode=ColorMode.IMAGE_BW)\n",
    "instance_result = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\")).get_image()\n",
    "\n",
    "v = Visualizer(im[:, :, ::-1], coco_metadata, scale=1.2, instance_mode=ColorMode.IMAGE_BW)\n",
    "semantic_result = v.draw_sem_seg(outputs[\"sem_seg\"].argmax(0).to(\"cpu\")).get_image()\n",
    "\n",
    "print(\"Panoptic segmentation (top), instance segmentation (middle), semantic segmentation (bottom)\")\n",
    "cv2_imshow(np.concatenate((panoptic_result, instance_result, semantic_result), axis=0)[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4bd7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imwrite(\"/pt/segmentation/output/panoptic_result_\" + image_name, panoptic_result)\n",
    "#cv2.imwrite(\"/pt/segmentation/output/instance_result_\" + image_name, instance_result)\n",
    "#cv2.imwrite(\"/pt/segmentation/output/semantic_result_\" + image_name, semantic_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf4238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_vis = np.concatenate((panoptic_result, instance_result, semantic_result), axis=1)\n",
    "cv2.imwrite(\"/pt/segmentation/output/combined_result_\" + image_name, combined_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cee1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from PIL import Image\n",
    "print(\"Panoptic segmentation (left), instance segmentation (middle), semantic segmentation (right)\")\n",
    "display.display(PIL.Image.fromarray(combined_vis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c47b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

version: '3'
services:
  nvidia:
    profiles: ["gpu"]
    container_name: oggora-gpu
    image: nvidia/cuda:12.0.0-base-ubuntu22.04
    command: nvidia-smi
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  tensorflow:
    profiles: ["tf"]
    build:
      context: ./tensorflow
    container_name: oggora-tf
    image: oggora-tf:latest
    command: sh -c "/tmp/init.sh"
    ports:
      - 8888:8888
    volumes:
      - ./tensorflow/share:/tf
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  pytorch:
    profiles: ["pt"]
    build:
      context: ./pytorch
      args:
        IMAGE_TYPE: devel
        CUDA_VERSION: 12.2.2
        UBUNTU_VERSION: 22.04
    container_name: oggora-pt
    image: oggora-pt:latest
    command: sh -c "/tmp/init.sh"
    ports:
      - 8888:8888
    volumes:
      - ./pytorch/share:/pt
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      default:
networks:
  default: